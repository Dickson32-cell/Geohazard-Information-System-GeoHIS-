"""create initial tables

Revision ID: 54e3a8625b52
Revises: 
Create Date: 2026-01-19 18:17:56.797114+00:00

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '54e3a8625b52'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('hazard_events',
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.Column('project_id', sa.String(length=36), nullable=True),
    sa.Column('hazard_type', sa.Enum('flood', 'landslide', 'erosion', name='hazardtype'), nullable=False),
    sa.Column('geometry', sa.String(), nullable=False),
    sa.Column('event_date', sa.DateTime(), nullable=False),
    sa.Column('severity', sa.Enum('low', 'medium', 'high', 'extreme', name='severity'), nullable=False),
    sa.Column('description', sa.String(), nullable=True),
    sa.Column('damage_estimate', sa.Float(), nullable=True),
    sa.Column('casualties', sa.Integer(), nullable=True),
    sa.Column('data_source', sa.String(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('infrastructure_assets',
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.Column('project_id', sa.String(length=36), nullable=True),
    sa.Column('asset_type', sa.Enum('school', 'hospital', 'road', 'bridge', 'building', name='assettype'), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('geometry', sa.String(), nullable=False),
    sa.Column('population_served', sa.Integer(), nullable=True),
    sa.Column('vulnerability_score', sa.Float(), nullable=False),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('project_datasets',
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.Column('project_id', sa.String(length=36), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('file_type', sa.String(length=50), nullable=False),
    sa.Column('file_path', sa.String(length=500), nullable=False),
    sa.Column('file_size_bytes', sa.Integer(), nullable=True),
    sa.Column('file_hash', sa.String(length=64), nullable=True),
    sa.Column('record_count', sa.Integer(), nullable=True),
    sa.Column('column_names', sa.JSON(), nullable=True),
    sa.Column('coordinate_columns', sa.JSON(), nullable=True),
    sa.Column('bounds', sa.JSON(), nullable=True),
    sa.Column('quality_score', sa.Float(), nullable=True),
    sa.Column('quality_report', sa.JSON(), nullable=True),
    sa.Column('uploaded_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('spatial_layers',
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.Column('project_id', sa.String(length=36), nullable=True),
    sa.Column('layer_name', sa.String(), nullable=False),
    sa.Column('layer_type', sa.Enum('dem', 'slope', 'drainage', 'landuse', 'soil', 'geology', name='layertype'), nullable=False),
    sa.Column('file_path', sa.String(), nullable=False),
    sa.Column('layer_metadata', sa.JSON(), nullable=True),
    sa.Column('acquisition_date', sa.Date(), nullable=False),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('project_analyses',
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.Column('project_id', sa.String(length=36), nullable=False),
    sa.Column('dataset_id', sa.String(length=36), nullable=True),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('hazard_type', sa.Enum('flood', 'landslide', 'erosion', name='hazardtype'), nullable=False),
    sa.Column('method', sa.Enum('ahp', 'frequency_ratio', 'topsis', 'fuzzy_ahp', 'ensemble', 'machine_learning', name='analysismethod'), nullable=False),
    sa.Column('parameters', sa.JSON(), nullable=False),
    sa.Column('random_seed', sa.Integer(), nullable=True),
    sa.Column('status', sa.Enum('pending', 'running', 'completed', 'failed', name='analysisstatus'), nullable=True),
    sa.Column('progress', sa.Float(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('results_summary', sa.JSON(), nullable=True),
    sa.Column('results_file_path', sa.String(length=500), nullable=True),
    sa.Column('validation_metrics', sa.JSON(), nullable=True),
    sa.Column('sensitivity_results', sa.JSON(), nullable=True),
    sa.Column('uncertainty_results', sa.JSON(), nullable=True),
    sa.Column('software_versions', sa.JSON(), nullable=True),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.ForeignKeyConstraint(['dataset_id'], ['project_datasets.id'], ),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('hazard_zones',
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.Column('project_id', sa.String(length=36), nullable=True),
    sa.Column('analysis_id', sa.String(length=36), nullable=True),
    sa.Column('hazard_type', sa.Enum('flood', 'landslide', 'erosion', name='hazardtype'), nullable=False),
    sa.Column('geometry', sa.String(), nullable=False),
    sa.Column('risk_level', sa.Enum('very_low', 'low', 'moderate', 'high', 'very_high', name='risklevel'), nullable=False),
    sa.Column('risk_score', sa.Float(), nullable=False),
    sa.Column('analysis_date', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.Column('analysis_parameters', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['analysis_id'], ['project_analyses.id'], ),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('project_exports',
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.Column('project_id', sa.String(length=36), nullable=False),
    sa.Column('analysis_id', sa.String(length=36), nullable=True),
    sa.Column('export_type', sa.String(length=50), nullable=False),
    sa.Column('format', sa.String(length=20), nullable=False),
    sa.Column('file_path', sa.String(length=500), nullable=False),
    sa.Column('file_size_bytes', sa.Integer(), nullable=True),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.ForeignKeyConstraint(['analysis_id'], ['project_analyses.id'], ),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('project_exports')
    op.drop_table('hazard_zones')
    op.drop_table('project_analyses')
    op.drop_table('spatial_layers')
    op.drop_table('project_datasets')
    op.drop_table('infrastructure_assets')
    op.drop_table('hazard_events')
    # ### end Alembic commands ###